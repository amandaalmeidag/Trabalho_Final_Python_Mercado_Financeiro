{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyU4e+aEKAlkyXQvzXS5fj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandaalmeidag/Trabalho_Final_Python_Mercado_Financeiro/blob/main/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra a tabela que contém as informações das empresas\n",
        "table = soup.find(\"table\", class_=\"table-portfolio\")\n",
        "\n",
        "# Extrai as informações das empresas\n",
        "empresas = []\n",
        "for row in table.find_all(\"tr\"):\n",
        "    cells = row.find_all(\"td\")\n",
        "    if len(cells) > 1:\n",
        "        empresa = {\n",
        "            \"Nome\": cells[1].text.strip(),\n",
        "            \"Código\": cells[2].text.strip(),\n",
        "            \"Setor\": cells[3].text.strip(),\n",
        "            \"Segmento\": cells[4].text.strip()\n",
        "        }\n",
        "        empresas.append(empresa)\n",
        "\n",
        "# Exibe as informações das empresas\n",
        "for empresa in empresas:\n",
        "    print(empresa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "8BV7TCG4QXLc",
        "outputId": "c96e6d6b-9f47-40a1-efa6-c34cf911c97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c32452dda739>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Extrai as informações das empresas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mempresas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"td\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra o elemento que contém as informações das empresas\n",
        "element = soup.find(\"div\", class_=\"list-title\")\n",
        "\n",
        "# Extrai as informações das empresas\n",
        "empresas = element.text.strip()\n",
        "\n",
        "# Exibe as informações das empresas\n",
        "print(empresas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "H-TVZ7zXRjzn",
        "outputId": "cd844a31-9b0f-47f8-ae0f-80ae0c92a7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-500df19203f2>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Extrai as informações das empresas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mempresas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Exibe as informações das empresas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra o texto que contém as informações das empresas\n",
        "text = soup.get_text()\n",
        "\n",
        "# Procura por padrões de nomes de empresas\n",
        "empresas = []\n",
        "pattern = \"• (.+)\"\n",
        "matches = re.findall(pattern, text)\n",
        "if matches:\n",
        "    empresas = [match.strip() for match in matches]\n",
        "\n",
        "# Exibe as informações das empresas\n",
        "for empresa in empresas:\n",
        "    print(empresa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "AkqFpzDAQp4W",
        "outputId": "00ac99e2-5d81-4700-c472-a6973c700f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6097900253d1>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mempresas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"• (.+)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mempresas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra o texto que contém as informações das empresas\n",
        "text = soup.get_text()\n",
        "\n",
        "# Procura por padrões de nomes de empresas\n",
        "empresas = []\n",
        "pattern = \"• (.+)\"\n",
        "matches = re.findall(pattern, text)\n",
        "if matches:\n",
        "    empresas = [match.strip() for match in matches]\n",
        "\n",
        "# Exibe as informações das empresas\n",
        "for empresa in empresas:\n",
        "    print(empresa)\n"
      ],
      "metadata": {
        "id": "aUlQRX7eQoox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra o elemento que contém as informações das empresas\n",
        "element = soup.find(\"div\", text=\"Fazem parte da carteira:\")\n",
        "\n",
        "# Extrai as informações das empresas\n",
        "empresas = []\n",
        "for sibling in element.find_next_siblings(\"li\"):\n",
        "    empresas.append(sibling.text.strip())\n",
        "\n",
        "# Exibe as informações das empresas\n",
        "for empresa in empresas:\n",
        "    print(empresa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "n4wndH_vSOWw",
        "outputId": "a5b1b0bb-065e-473e-acd1-52b5db23321e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-3062c9975e03>:14: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  element = soup.find(\"div\", text=\"Fazem parte da carteira:\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3062c9975e03>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Extrai as informações das empresas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mempresas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msibling\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_next_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"li\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mempresas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msibling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_next_siblings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLNjbRIXkTkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição HTTP ao site\n",
        "response = requests.get(url)\n",
        "content = response.content\n",
        "\n",
        "# Cria um objeto BeautifulSoup\n",
        "soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "# Encontra o elemento que contém as informações das empresas\n",
        "element = soup.find(lambda tag: tag.name == \"div\" and \"Fazem parte da carteira:\" in tag.text)\n",
        "\n",
        "# Extrai as informações das empresas\n",
        "if element:\n",
        "    empresas = [sibling.text.strip() for sibling in element.find_next_siblings(\"li\")]\n",
        "\n",
        "    # Exibe as informações das empresas\n",
        "    for empresa in empresas:\n",
        "        print(empresa)\n",
        "else:\n",
        "    print(\"Elemento não encontrado.\")\n"
      ],
      "metadata": {
        "id": "A0gKdAelSVdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", text=\"Aeris\")\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Separa os nomes das empresas por vírgula\n",
        "    companies = paragraph_text.split(\",\")\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "kHDoXh4YkV5w",
        "outputId": "ab08478a-62f6-4efe-9cab-e6459c1b85f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-eb282b166168>:19: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  paragraph = soup.find(\"p\", text=\"Aeris\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-eb282b166168>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Extrai o texto do parágrafo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mparagraph_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Separa os nomes das empresas por vírgula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o primeiro parágrafo que começa com o texto \"Aeris\"\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai os nomes das empresas dos irmãos subsequentes\n",
        "    companies = []\n",
        "    for sibling in paragraph.find_next_siblings():\n",
        "        text = sibling.get_text(strip=True)\n",
        "        if not text or text.startswith(\",\"):\n",
        "            break\n",
        "        companies.append(text.strip())\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company)\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBf46sSRkrW9",
        "outputId": "f89ead3d-13dd-4d14-9dc5-88d0dbf37a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De 02/01/2023 a 22/01/2023, a Americanas S.A. também fez parte da carteira, deixando de fazer parte em 23/01/2023.\n",
            "De 02/01/2023 a 15/05/2023, a Light S.A. também fez parte da carteira, deixando de fazer parte em 16/05/2023.\n",
            "As versões finais do questionário ISE B3 2022 encontram-se disponíveis para download no link abaixo. Nesse link também consta um documento com a Visão Geral do questionário, seu Glossário e uma versão do questionário com marcas de alteração em relação à versão 2021.\n",
            "Questionário ISE B3 2022\n",
            "2021/2022\n",
            "A 17ª carteira do ISE B3 foi anunciada em 29/12/2021 e vigorou no período de 03 de janeiro de 2022 a 30 de dezembro de 2022. A carteira anunciada naquela ocasião reunia 46 ações, de 46 companhias, pertencentes a 27 setores. Juntas, essas companhias somavam R$ 1,74 trilhão em valor de mercado, 38,26% do total do valor de mercado das companhias com ações negociadas na B3, com base no fechamento de 30 de dezembro de 2021. Em 02/05/2022 ocorreu um rebalanceamento dos critérios de inclusão, quando duas novas empresas passaram a fazer parte da carteira do ISE B3.\n",
            "A carteira 2022 do ISE B3 foi a primeira selecionada por meio de uma nova metodologia, que além das respostas ao questionário e análise de evidências, considerou informações de duas fontes externas. A primeira fonte externa foi o resultado das empresas no CDP 2021, incorporando informações referentes à dimensão Mudança do Clima. A segunda foram as análises de reputação das companhias, realizadas pela RepRisk.\n",
            "Fazem parte da carteira:\n",
            "AES Brasil Energia, Americanas S.A., Ambipar, Arezzo, Azul, Bradesco, Banco do Brasil, BTG Pactual, Braskem, BRF, CCR, Cemig, Cia Brasileira de Distribuição, Cielo, Copel, Cosan, CPFL, Dexco, Ecorodovias, EDP, Eletrobrás, Engie, Fleury, Iochpe Maxion, Itaú Unibanco, Itausa, Klabin, Light, Lojas Renner, M Dias Branco, Magazine Luiza, Marfrig, Minerva, Movida, MRV, Natura, Neoenergia, Raia Drogasil, Rumo, Santander, Simpar, Sul America, Suzano, Telefônica, Tim, Via, Vibra e Weg.\n",
            "As versões finais do questionário ISE B3 2021 encontram-se disponíveis para download no link abaixo, nos seguintes formatos: Word e PDF. Nesse link também consta um documento com a Visão Geral do questionário, seu Glossário e uma planilha com um \"de-para\" desta versão do questionário em relação à sua versão 2020.\n",
            "Questionário ISE B3 2021\n",
            "2020/2021\n",
            "A 16ª carteira do ISE B3 foi anunciada em 01/12/2020 e vigorou no período de 04 de janeiro de 2021 a 30 de dezembro de 2021. A carteira reúne 46 ações, de 40 companhias, pertencentes a 15 setores. Juntas, as companhias somam R$ 1,8 trilhão em valor de mercado, 38% do total do valor das companhias com ações negociadas na B3, com base no fechamento de 25/11/2020.Clique aquipara acessar o release da B3 sobre o lançamento da carteira.\n",
            "Fazem parte da carteira:\n",
            "AES Brasil Energia, B2W, Banco do Brasil, BR Distribuidora, Bradesco, BRF, BTG Pactual, CCR, Cemig, Cielo, Copel, Cosan, CPFL, Duratex, Ecorodovias, EDP, Eletrobras, Engie, Fleury, GPA, Itaú Unibanco, Itaúsa, Klabin, Light, Lojas Americanas, Lojas Renner, M. Dias Branco, Marfrig, Minerva, Movida, MRV, Natura, Neoenergia, Petrobras, Santander, Sendas (Assaí)*, Suzano, Telefônica, Tim e Weg.\n",
            "*Sendas (Assaí) passou a compor a carteira em 01/03/2021, pela cisão parcial da Cia. Brasileira de Distribuição (GPA).\n",
            "As versões finais do questionário ISE B3 2020 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE B3 2020\n",
            "2019/2020\n",
            "A 15ª carteira do ISE B3 foi anunciada em 29/11/2019 e vigora no período de 06 de janeiro de 2020 a 01 de janeiro de 2021. A carteira reúne 36 ações de 30 companhias. Além disso, representa 15 setores e soma R$ 1.640.789.376.818,99 em valor de mercado. Esse montante equivale a 37,62% do total do valor das companhias com ações negociadas na B3, conforme base atualizada em 26/11/2019.\n",
            "Fazem parte da carteira:\n",
            "AES Tiete, B2W, Banco do Brasil, BR Distribuidora, Bradesco, Braskem, BRF, CCR, Cemig, Cielo, Copel, Duratex, Ecorodovias, EDP, Eletrobras, Engie, Fleury, Itaú Unibanco, Itaúsa, Klabin, Light, Lojas Americanas, Lojas Renner, Movida, MRV, Natura, Santander, Telefônica, Tim e Weg.\n",
            "As versões finais do questionário ISE B3 2019 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE B3 2019\n",
            "2018/2019\n",
            "A 14ª carteira do ISE B3 foi anunciada em 29/11/2018 e vigora no período de 07 de janeiro de 2019 a 03 de janeiro de 2020. A carteira reúne 33 ações de 28 companhias. Além disso, representa 12 setores e soma R$ 1.474.540.575.401,55 em valor de mercado. Esse montante equivale a 38,74% do total do valor das companhias com ações negociadas na B3, conforme base atualizada em 06/05/2019.\n",
            "Fizeram parte da carteira:\n",
            "AES Tiete, B2W, Banco do Brasil, Bradesco, Braskem, CCR, Cemig, Cielo, Copel, Duratex, Ecorodovias, EDP, Eletrobras, Eletropaulo, Engie, Fleury, Itaú Unibanco, Itaúsa, Klabin, Light, Lojas Americanas, Lojas Renner, MRV, Natura, Santander, Telefônica, Tim e Weg.\n",
            "As versões finais do questionário ISE B3 2018 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE B3 2018\n",
            "2017/2018\n",
            "A 13ª carteira do ISE B3 foi anunciada em 23/11/2017 e vigorou de 08 de janeiro de 2018 a 04 de janeiro de 2019. A carteira reuniu 33 ações de 30 companhias, representando 12 setores e somando R$ 1,28 trilhão em valor de mercado, equivalente a 41,47% do total do valor das companhias com ações negociadas na B3, com base no fechamento de 21/11/2017.Saiba mais\n",
            "Fizeram parte da carteira:\n",
            "AES Tiete, B2W, Banco do Brasil, Bradesco, Braskem, CCR, Celesc, Cemig, Cielo, Copel, CPFL, Duratex, Ecorodovias, EDP, Eletropaulo, Engie, Fibria, Fleury, Itaú Unibanco, Itaúsa, Klabin, Light, Lojas Americanas, Lojas Renner, MRV, Natura, Santander, Telefônica, Tim e Weg.\n",
            "As versões finais do questionário ISE 2017 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE B3 2017\n",
            "2016/2017\n",
            "A 12ª carteira do ISE B3 foi anunciada em 24/11/2016 e vigorou de 02 de janeiro de 2017 a 05 de janeiro de 2018. A carteira reuniu 38 ações de 34 companhias, representando 15 setores e somando R$ 1,31 trilhão em valor de mercado, o equivalente a 52,14% do total do valor das companhias com ações negociadas na Bolsa com base no fechamento de 22/11/2016.\n",
            "Fizeram parte da carteira:\n",
            "AES Tietê, B2W, Banco do Brasil, Bradesco, Braskem, BRF, CCR, Celesc, Cemig, Cielo, Copel, CPFL, Duratex, Ecorodovias, EDP, Eletrobras, Eletropaulo, Embraer, Engie*, Fibria, Fleury, Itaúsa, Itaú Unibanco, Klabin, Lojas Americanas, Lojas Renner, Light, MRV, Natura, Santander, SulAmerica, Telefônica, TIM e Weg.\n",
            "*Tractebel altera razão social para Engie em 21/07/2016.\n",
            "As versões finais do questionário ISE 2016 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE B3 2016\n",
            "2015/2016\n",
            "Anunciada em 26 de novembro de 2015, a 11ª carteira do ISE vigorou entre 04 de janeiro de 2016 a 29 de dezembro de 2016. A carteira reuniu 38 ações de 34 companhias, que representavam 16 setores e somavam R$ 960,52 bilhões em valor de mercado, o equivalente a 54,50% do total do valor das companhias com ações negociadas na Bolsa (em 24/11/2015).\n",
            "Fizeram parte da carteira*:\n",
            "AES Tietê, B2W Digital, Banco do Brasil, Bradesco, Braskem, BRF SA, CCR SA, Cemig, Cesp, Cielo, Copel, CPFL Energia, Energias BR (EDP) Duratex, Ecorodovias, Eletrobrás, Eletropaulo, Embraer, Engie Brasil Energia**, Even, Fleury, Klabin S/A, Fibria, Itau Unibanco, Itausa, Light S/A, Lojas Americanas, Lojas Renner, Natura, Telef Brasil (Telefônica), Tim Part S/A, Santander, SulAmerica e Weg.\n",
            "*Em 21/06/2016, a OI entrou em situação especial, deixando de fazer parte da carteira do ISE em 22/06/2016.\n",
            "**Em julho de 2016 a companhia Tractebel Energia alterou seu nome para Engie Brasil Energia.\n",
            "As versões finais do questionário ISE 2015 encontram-se disponíveis para download no link abaixo.\n",
            "Questionário ISE 2015\n",
            "2014/2015\n",
            "Anunciada em 26 de novembro de 2014 e vigorou entre 05 de janeiro de 2015 a 02 de janeiro de 2016. A carteira reúne 51 ações de 40 companhias, que representaram 19 setores e somaram R$ 1,22 trilhão em valor de mercado, o equivalente a 49,87% do total do valor das companhias com ações negociadas na B3 (em 24/11/2014).\n",
            "Das 40 empresas selecionadas, ingressaram: JSL, B2W Digital, Lojas Americanas e Lojas Renner, as três últimas responsáveis pelo ingresso do setor \"Comércio\" ao ISE.\n",
            "Compuseram a carteira 2015:\n",
            "AES Tietê, B2W Digital, Banco do Brasil, Bradesco, Braskem, BRF SA, BicBanco, CCR SA, Cemig,Cielo, Coelce, Copel,CPFL Energia, Duratex, Ecorodovias,Eletrobrás, Eletropaulo, Embraer, Energias BR (EDP), Even, Fibria, Fleury, Gerdau, Gerdau Met, Itau Unibanco, Itausa, JSL, Klabin S/A, Light S/A, Lojas Americanas, Lojas Renner, Natura, Sabesp,Santander, SulAmerica, Telef Brasil (Telefônica), Tim Part S/A,   Tractebel,  Vale e Weg.\n",
            "Questionário ISE 20142013/2014A nona carteira do ISE foi anunciada no dia 28 de novembro de 2013 e vigorou de 06 de janeiro de 2014 a 02 de janeiro de 2015. A carteira reuniu 51 ações de 40 companhias, que representaram 18 setores e somaram R$ 1,14 trilhão em valor de mercado, o equivalente a 47,16% do total do valor das companhias com ações negociadas na Bolsa (em 26/11/2013).Compuseram a carteira 2014:AES Tietê, Banco do Brasil, BicBanco, Bradesco, Braskem, BRF, CCR, Cemig, Cesp, Cielo, Coelce, Copasa, Copel, CPFL, Duratex, Ecorodovias, EDP, Eletrobras, Eletropaulo, Embraer, Even, Fibria, Fleury, Gerdau, Itaú-Unibanco, Itausa, Klabin, Light, MET Gerdau, Natura, OI, Sabesp, Santander, SulAmerica, Suzano, Telefonica, TIM, Tractebel, Vale e Weg.Questionário ISE 20132012/2013A oitava carteira do ISE, que vigorou de 07 de janeiro de 2013 a 03 de janeiro de 2014, reuniu 51 ações de 37 companhias. Elas representaram 16 setores e somaram pouco mais de R$1 trilhão em valor de mercado, o equivalente a 44,81% do total do valor das companhias com ações negociadas na B3 (em 29/11/2012).Compuseram a carteira 2013:AES Tiete, Banco do Brasil, Bicbanco, Bradesco, Braskem, BRF Brasil Foods, CCR, Cemig, Cesp, Copel, Coelce, Copasa, CPFL Energia, Duratex, Energias do Brasil, Ecorodovias, Eletrobras, Eletropaulo, Even, Fibria, Gerdau, Gerdau Met, Itausa, Itau Unibanco, Light S/A, Natura, Sabesp, Santander, Sulamérica, Suzano Papel, Telefonica, Telemar, Tim Part S/A, Tractebel, Ultrapar, Vale e Weg.Questionário ISE 20122011/2012A sétima carteira do ISE, vigorou de 02 de janeiro a 31 de dezembro de 2012, reúne 51 ações de 38 companhias. Elas representaram 18 setores e somaram R$961 bilhões em valor de mercado, o equivalente a 43,72% do total do valor das companhias com ações negociadas na Bolsa (em 23/11/2011).Compuseram a carteira 2012:AES Tiete, Anhanguera, Banco do Brasil, Bicbanco, Bradesco, Braskem, BRF Brasil Foods, CCR, Cemig, Cesp, Copel, Coelce, Copasa, CPFL Energia, Duratex, Energias do Brasil, Ecorodovias, Eletrobras, Eletropaulo, Embraer, Even, Fibria, Gerdau, Gerdau Met, Itausa, Itau Unibanco, Light S/A, Natura, Redecard, Sabesp, Santander, Sulamérica, Suzano Papel, Telemar, Tim Part S/A, Tractebel, Ultrapar e Vale.Questionário ISE 20112010/2011A sexta carteira do ISE, vigorou de 3 de janeiro de 2011 a 29 de dezembro, reunindo 47 ações de 38 companhias que representaram 18 setores e somaram R$ 1,17 trilhão em valor de mercado, o equivalente a 46,1% do valor de mercado total das companhias com ações negociadas na B3 (em 24/11/2010).Compuseram a carteira 2011:AES Tietê, Anhanguera, Bicbanco, Banco do Brasil, Bradesco, Braskem, BRF Foods, Cemig, Cesp, Coelce, Copasa, Copel, CPFL Energia, Duratex, Eletrobras, Eletropaulo, Embraer, Energias BR, Even, Fibria, Gerdau, Gerdau Met, Inds Romi, Itau SA, Itau Unibanco, Light S/A, Natura, Redecard, Sabesp, Santander, Sul América, Suzano Papel, Telemar, Tim Part S/A, Tractebel, Ultrapar, Vale e Vivo.Questionários ISE 20102009/2010A quinta carteira do ISE vigorou de 1 de dezembro de 2009 a 31 de dezembro de 2010. Reuniu 43 ações de 36 companhias, representando 15 setores e somando R$730 bilhões em valor de mercado - o equivalente a 32,21% do valor de mercado total das companhias com ações negociadas na Bolsa (em 24/11/2009).Compuseram a carteira 2010:AES Tietê, Aracruz,Banco do Brasil,Bradesco, Braskem, Cemig, Cesp, Coelce, Copel, CPFL Energia, Dasa, Duratex, Eletrobras, Eletropaulo, Embraer, Energias BR, Even, Gerdau, Gerdau Met, Inds Romi, Itau S/A, Itau Unibanco, Light S/A, Natura, Perdigão, Redecard, Sabesp, Sul América, Sadia, Suzano Papel, Telemar, Tim Part S/A, Tractebel, Usiminas e Vivo.Questionários ISE 20092008/2009Vigorou de 1º de dezembro de 2008 a30 de novembro de 2009, contou com 38 ativos de 30 companhias de 12 setores que totalizaram R$372 bilhões em valor de mercado. Esse montante correspondia a 30,7% da capitalização total das 394 empresas com ações negociadas na Bolsa (R$ 1,21 trilhão, em 21/11/2009).A quarta carteira do ISE, esteve composta por ações das seguintes empresas:AES Tiete, Banco do Brasil, Bradesco, Braskem, Celesc, Cemig, Cesp, Coelce, CPFL Energia, DASA, Duratex, Eletrobrás, Eletropaulo, Embraer, Energias do Brasil (EDP), Gerdau, Metalúrgica Gerdau, Itaubanco, Light; Natura, Odontoprev, Perdigão, Sabesp, Sadia, Suzano Papel, Telemar, TIM Participações, Tractebel, Unibanco e VCP.Questionário ISE 20082007/2008A carteira contou com 40 ações emitidas por 32 empresas de 13 setores totalizando, naquela época, R$927 bilhões em valor de mercado. Esse montante correspondia a 39,6% da capitalização total da Bolsa, que em dezembro de 2007 era de R$ 2,3 trilhões.A terceira carteira do ISE, esteve composta por ações das seguintes empresas:AES Tietê, Acesita, Aracruz, Banco do Brasil, Bradesco, Braskem, CCR Rodovias, Cemig, Cesp, Coelce, Copel, CPFL Energia, DASA, Eletrobrás, Eletropaulo, Embraer, Energias do Brasil (EDP), Gerdau, Metalúrgica Gerdau, Iochpe-Maxion, Itaubanco, Light, Natura, Perdigão, Petrobrás, Sabesp, Sadia, Suzano Papel, Suzano Petroquímica, Tractebel, VCP e Weg.Questionário ISE 20072006/2007A segunda carteira do ISE, vigorou de 1º de dezembro de 2006 à 30 de novembro de 2007, contando com 42 ações de 34 companhias e 14 setores, totalizando R$ 996 bilhões em valor de mercado (42,6% do total da bolsa em 1º de dezembro de 2006).Fizeram parte da segunda carteira do ISE:Acesita, All América Latina, Aracruz, Arcelor BR, Banco do Brasil, Bradesco, Braskem, CCR Rodovias, Celesc, Cemig, Coelce, Copel, CPFL Energia, Dasa, Eletropaulo, Embraer, Energias do Brasil (EDP), Gerdau, Metalúrgica Gerdau, Gol, Iochpe-Maxion, Itaubanco, Itausa, Localiza, Natura, Perdigão, Petrobrás, Suzano Papel, Suzano PETR, TAM, Tractebel, Ultrapar, Unibanco e VCP.Questionário ISE 20062005/2006A primeira carteira do ISE, vigorou de 1º de dezembro de 2005 a 30 de novembro de 2006. Fizeram parte as seguintes empresas:ALL America Latina, Aracruz, Belgo Mineira, Banco do Brasil, Bradesco, Braskem, CCR Rodovias, Celesc, Cemig, Cesp, Copel, Copesul, CPFL Energia, DASA, Eletrobrás, Eletropaulo, Embraer, Gol, Iochpe-Maxion, Itaubanco, Itausa, Natura, Perdigão, Suzano Papel, Tractebel, Unibanco, VCP e Weg.Questionário ISE 2005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Extrai os nomes das empresas separados por vírgula usando expressão regular\n",
        "    companies = re.findall(r\"Aeris(.*?)(?=,|$)\", paragraph_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU-G_3XHlKa-",
        "outputId": "f1db6d84-a700-4c36-9b99-224bc15da9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Extrai os nomes das empresas separados por vírgula usando expressão regular\n",
        "    companies = re.findall(r\"Aeris,?(.*?)(?=,|$)\", paragraph_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8y204uLlwUF",
        "outputId": "7e845094-8362-4fae-da1f-5e1886ce7e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AES Brasil Energia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Extrai os nomes das empresas separados por vírgula usando expressão regular\n",
        "    companies = re.findall(r\"[^,]+\", companies_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrcnFJc0mrf8",
        "outputId": "460a5c99-851c-4d03-ba16-e732fa8b0b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Extrai os nomes das empresas separados por vírgula ou conector \"e\" usando expressão regular\n",
        "    companies = re.findall(r\"[^,]+(?: e [^,]+)?\", companies_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LpaxtCynM_9",
        "outputId": "0ef5232a-2696-4e2c-e665-3cbf3af091f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Extrai os nomes das empresas separados por vírgula usando expressão regular\n",
        "    companies = re.findall(r\"[^,]+(?: e [^,]+)?(?:,|$)\", companies_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Asl2_xFnxHc",
        "outputId": "74d1ab18-cfac-4d47-8aad-e8c3ed543ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris,\n",
            "AES Brasil Energia,\n",
            "Aliansce Sonae,\n",
            "Ambev,\n",
            "Ambipar,\n",
            "Arezzo,\n",
            "Azul,\n",
            "B3 S.A.,\n",
            "Banco do Brasil,\n",
            "Banco Pan,\n",
            "Bradesco,\n",
            "Braskem,\n",
            "BRF,\n",
            "BTG Pactual,\n",
            "CCR,\n",
            "Cemig,\n",
            "Cia Brasileira de Alumínio,\n",
            "Cia Brasileira de Distribuição,\n",
            "Cielo,\n",
            "Cogna Educação,\n",
            "Copel,\n",
            "Cosan,\n",
            "CPFL,\n",
            "CTEEP,\n",
            "Dexco,\n",
            "Diagnósticos da América,\n",
            "Ecorodovias,\n",
            "EDP,\n",
            "Eletrobrás,\n",
            "Eneva,\n",
            "Engie,\n",
            "Fleury,\n",
            "Gafisa,\n",
            "Grendene,\n",
            "Guararapes,\n",
            "Hypera,\n",
            "Iochpe Maxion,\n",
            "Irani Papel e Embalagem,\n",
            "Itaú Unibanco,\n",
            "Itausa,\n",
            "Klabin,\n",
            "Lojas Renner,\n",
            "M. Dias Branco,\n",
            "Magazine Luiza,\n",
            "Marfrig,\n",
            "Minerva,\n",
            "Movida,\n",
            "MRV,\n",
            "Natura,\n",
            "Neoenergia,\n",
            "Raia Drogasil,\n",
            "Raízen,\n",
            "Rede D’or,\n",
            "Rumo,\n",
            "Sanepar,\n",
            "Santander,\n",
            "Santos Brasil,\n",
            "Sendas,\n",
            "Simpar,\n",
            "SLC Agrícola,\n",
            "Suzano,\n",
            "Telefônica,\n",
            "Tim,\n",
            "Usiminas,\n",
            "Vamos S.A.,\n",
            "Via,\n",
            "Vibra e Weg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x13pn5RNoFat",
        "outputId": "b13782bf-ce91-4eeb-a991-79fbcdcd5959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    last_company = companies_list[-1].split(\" e \")\n",
        "    companies_list = companies_list[:-1] + last_company\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otfU5MjHoZQ6",
        "outputId": "e576213e-867f-4fbb-9559-5e94bdaee4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra\n",
            "Weg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    last_company = companies_list[-1].replace(\".\", \"\")\n",
        "    companies_list = companies_list[:-1] + [last_company]\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZFO70gEovtt",
        "outputId": "1a764afe-d847-48ee-caeb-ff1f403fc414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Remove o ponto da última empresa e adiciona em uma linha separada\n",
        "    last_company = companies_list[-1].replace(\".\", \"\")\n",
        "    companies_list = companies_list[:-1] + [last_company, \"Weg\"]\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1FNDWgWo6L_",
        "outputId": "1cc6b765-96a7-421a-8368-f59cf98a5e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    last_company = companies_list[-1].replace(\".\", \"\")\n",
        "    companies_list = companies_list[:-1] + [last_company]\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRoXxTW8pU2b",
        "outputId": "2a09b651-1a2c-4d98-ba6e-7955e840225e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra e Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    last_company = companies_list[-1].replace(\".\", \"\")\n",
        "    companies_list = companies_list[:-1] + last_company.split(\" e \") + [\"Weg\"]\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofKR7Z9qpyVH",
        "outputId": "0b26f79c-efef-4b1a-e8db-0c5301c6a03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra\n",
            "Weg\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Encontra o índice inicial do parágrafo\n",
        "    start_index = paragraph_text.index(\"Aeris\")\n",
        "\n",
        "    # Encontra o índice final do parágrafo\n",
        "    end_index = paragraph_text.index(\"Weg.\")\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = paragraph_text[start_index:end_index + 4]\n",
        "\n",
        "    # Remove a vírgula ao final de cada empresa separada por linha\n",
        "    companies_text = re.sub(r',\\s*$', '', companies_text, flags=re.MULTILINE)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r',\\s*', companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    last_company = companies_list[-1].replace(\".\", \"\")\n",
        "    companies_list = companies_list[:-1] + last_company.split(\" e \")\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.strip())\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX5Cbk6Tp9UB",
        "outputId": "4e931fdd-b6db-4aa9-f06b-00a815273f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A.\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A.\n",
            "Via\n",
            "Vibra\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = re.search(r\"Aeris(.*?Weg\\.?)\", paragraph_text).group(0)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r\",\\s*(?=.{2,}$)\", companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    companies_list = companies_list[:-1] + last_company.split(\" e \")\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.rstrip(\".,\"))\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-JRTlWMqbFO",
        "outputId": "7ed0c9b0-7630-4e1e-9b82-2332af5c428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A\n",
            "Via\n",
            "Vibra\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = re.search(r\"Aeris(.*?Weg\\.?)\", paragraph_text).group(0)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r\",\\s*(?=.{2,}$)\", companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    companies_list[-1] = companies_list[-1].rstrip(\".,\")\n",
        "    last_company = companies_list[-1].split(\" e \")\n",
        "    companies_list = companies_list[:-1] + last_company\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.rstrip(\".,\"))\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvRDuDzjtFNh",
        "outputId": "80b14174-2e0c-4919-9daf-e268d068091b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A\n",
            "Via\n",
            "Vibra\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQXiHjSJxs7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrxme9dgjbgt",
        "outputId": "db195064-57f7-4123-b35e-16a852f32fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Carrega o arquivo\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Agora vamos ler o arquivo carregado usando pandas\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  df = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')), sep=';')\n",
        "\n",
        "# Exibe as primeiras linhas do DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "pA-1SRa_jhTf",
        "outputId": "f0316123-9e4e-4c66-9a74-84ccddbc5f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6d474e4-b531-497d-8677-8107d728ab9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6d474e4-b531-497d-8677-8107d728ab9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Taxa_Media_Crescimento.csv to Taxa_Media_Crescimento.csv\n",
            "User uploaded file \"Taxa_Media_Crescimento.csv\" with length 586 bytes\n",
            "  ISEE - 2013 2023 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
            "0              Ano       2013       2014       2015       2016       2017   \n",
            "1             2014      -1,94        NaN        NaN        NaN        NaN   \n",
            "2             2015      -7,58      -12,9        NaN        NaN        NaN   \n",
            "3             2016      -0,94      -0,44      13,79        NaN        NaN   \n",
            "4             2017       3,36       5,18      15,58       17,4        NaN   \n",
            "\n",
            "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \n",
            "0       2018       2019       2020       2021        2022       Anual  \n",
            "1        NaN        NaN        NaN        NaN         NaN    2.431,59  \n",
            "2        NaN        NaN        NaN        NaN         NaN    2.118,01  \n",
            "3        NaN        NaN        NaN        NaN         NaN    2.410,05  \n",
            "4        NaN        NaN        NaN        NaN         NaN    2.829,50  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a_PxwLtkinQ",
        "outputId": "f079b1eb-e006-4b6e-fae6-2231eb56eb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carrega o arquivo\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Agora vamos ler o arquivo carregado usando pandas\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  df = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')), sep=';')\n",
        "\n",
        "# Exibe as primeiras linhas do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Supondo que a coluna de datas é chamada 'Date' e está no formato 'YYYY-MM-DD'\n",
        "df['Year'] = pd.to_datetime(df['Date']).dt.year\n",
        "\n",
        "# Calcula a variação média do ISE por ano (altere 'ISE' se o nome da sua coluna for diferente)\n",
        "df_grouped = df.groupby('Year')['ISE'].mean().pct_change()\n",
        "\n",
        "# Plota o gráfico de linha da variação média do ISE por ano\n",
        "df_grouped.plot(kind='line', figsize=(10, 5))\n",
        "\n",
        "plt.title('Taxa média de variação do Índice ISE por ano')\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Taxa média de variação')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "pPXQ3H-0kkMS",
        "outputId": "40695872-b5da-4baf-95b2-0f714535ca57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-505df255-8f90-47a3-939a-ea334d00164a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-505df255-8f90-47a3-939a-ea334d00164a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Taxa_Media_Crescimento.csv to Taxa_Media_Crescimento (1).csv\n",
            "User uploaded file \"Taxa_Media_Crescimento.csv\" with length 586 bytes\n",
            "  ISEE - 2013 2023 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
            "0              Ano       2013       2014       2015       2016       2017   \n",
            "1             2014      -1,94        NaN        NaN        NaN        NaN   \n",
            "2             2015      -7,58      -12,9        NaN        NaN        NaN   \n",
            "3             2016      -0,94      -0,44      13,79        NaN        NaN   \n",
            "4             2017       3,36       5,18      15,58       17,4        NaN   \n",
            "\n",
            "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \n",
            "0       2018       2019       2020       2021        2022       Anual  \n",
            "1        NaN        NaN        NaN        NaN         NaN    2.431,59  \n",
            "2        NaN        NaN        NaN        NaN         NaN    2.118,01  \n",
            "3        NaN        NaN        NaN        NaN         NaN    2.410,05  \n",
            "4        NaN        NaN        NaN        NaN         NaN    2.829,50  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-219b1f73cabe>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Supondo que a coluna de datas é chamada 'Date' e está no formato 'YYYY-MM-DD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Calcula a variação média do ISE por ano (altere 'ISE' se o nome da sua coluna for diferente)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Date'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Fazendo o upload do arquivo CSV\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Garantindo que somente um arquivo foi enviado\n",
        "if len(uploaded.keys()) != 1:\n",
        "  print(\"Por favor, faça o upload de apenas um arquivo de cada vez.\")\n",
        "else:\n",
        "  filename = list(uploaded.keys())[0]  # Nome do arquivo\n",
        "\n",
        "  # Lendo o arquivo CSV\n",
        "  # Supomos que a primeira linha é o título (skiprows=1 ignora a primeira linha) e a segunda linha contém os nomes das colunas\n",
        "  df = pd.read_csv(filename, skiprows=1)\n",
        "\n",
        "  # Imprimindo o título da tabela\n",
        "  with open(filename, 'r') as f:\n",
        "    title = f.readline().strip()  # Lê a primeira linha (título) e remove espaços desnecessários\n",
        "  print(f\"Título da Tabela: {title}\\n\")\n",
        "\n",
        "  # Imprimindo o conteúdo da tabela\n",
        "  print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "veqFIjyCsNoV",
        "outputId": "3b72c589-f740-45a8-e2b5-8c16b217b5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20081246-f366-42c2-8bd5-bb57970ce733\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20081246-f366-42c2-8bd5-bb57970ce733\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Coleta de Dados Marmitaria Delivery - Página2.csv to Coleta de Dados Marmitaria Delivery - Página2.csv\n",
            "Título da Tabela: ISEE - Carteira do Dia 12/06/23,,,\n",
            "\n",
            "                      Código          Ação   Qtde. Teórica Part. (%)\n",
            "0                      GFSA3        GAFISA     100.082.905     0,083\n",
            "1                      AERI3         AERIS     462.097.561     0,086\n",
            "2                      GUAR3    GUARARAPES     166.833.255     0,123\n",
            "3                      RANI3         IRANI     207.858.909     0,214\n",
            "4                      AMBP3       AMBIPAR      89.303.276     0,227\n",
            "..                       ...           ...             ...       ...\n",
            "64                     RDOR3     REDE D OR     618.721.244     2,399\n",
            "65                     BBDC4      BRADESCO   1.226.523.575     2,486\n",
            "66                     NTCO3  GRUPO NATURA   1.477.004.465     2,833\n",
            "67                     LREN3  LOJAS RENNER   1.150.363.820      3,02\n",
            "68  Quantidade Teórica Total           NaN  61.651.430.185       100\n",
            "\n",
            "[69 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Lista de tickers das ações\n",
        "tickers = ['GFSA3.SA', 'AERI3.SA', 'GUAR3.SA', 'RANI3.SA', 'AMBP3.SA', 'CBAV3.SA', 'MOVI3.SA', 'MYPK3.SA',\n",
        "           'GRND3.SA', 'MRFG3.SA', 'ECOR3.SA', 'SIMH3.SA', 'DXCO3.SA', 'PCAR3.SA', 'BPAN4.SA', 'BEEF3.SA',\n",
        "           'MDIA3.SA', 'DASA3.SA', 'NEOE3.SA', 'MRVE3.SA', 'USIM5.SA', 'SLCE3.SA', 'AESB3.SA', 'VIIA3.SA',\n",
        "           'SAPR11.SA', 'VAMO3.SA', 'RAIZ4.SA', 'ARZZ3.SA', 'CIEL3.SA', 'ENBR3.SA', 'COGN3.SA', 'CPFE3.SA',\n",
        "           'FLRY3.SA', 'AZUL4.SA', 'ABEV3.SA', 'BRKM5.SA', 'WEGE3.SA', 'ASAI3.SA', 'STBP3.SA', 'CMIG4.SA',\n",
        "           'CPLE6.SA', 'HYPE3.SA', 'ENEV3.SA', 'RAIL3.SA', 'RADL3.SA', 'TIMS3.SA', 'ITSA4.SA', 'CCRO3.SA',\n",
        "           'ALSO3.SA', 'ITUB4.SA', 'BBAS3.SA', 'ELET3.SA', 'EGIE3.SA', 'TRPL4.SA', 'CSAN3.SA', 'VIVT3.SA',\n",
        "           'SANB11.SA', 'VBBR3.SA', 'SUZB3.SA', 'BRFS3.SA', 'MGLU3.SA', 'B3SA3.SA', 'BPAC11.SA', 'KLBN11.SA',\n",
        "           'RDOR3.SA', 'BBDC4.SA', 'NTCO3.SA', 'LREN3.SA']\n",
        "\n",
        "# Dicionário para guardar a categoria de cada ação\n",
        "categorias = {}\n",
        "\n",
        "# Buscando as categorias\n",
        "for ticker in tickers:\n",
        "  empresa = ticker.split('.')[0]  # Obtém o nome da empresa removendo o \".SA\"\n",
        "  info = yf.Ticker(ticker).info\n",
        "  categorias[empresa] = info['sector'] if 'sector' in info else 'Setor não disponível'\n",
        "\n",
        "# Transformando o dicionário em um DataFrame para visualização mais clara\n",
        "df = pd.DataFrame(list(categorias.items()), columns=['Ticker', 'Setor'])\n",
        "\n",
        "# Imprime o DataFrame\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdAV6-f5tzDR",
        "outputId": "f54a9b7f-0137-47d6-f545-7959628cecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Ticker               Setor\n",
            "0    GFSA3   Consumer Cyclical\n",
            "1    AERI3         Industrials\n",
            "2    GUAR3   Consumer Cyclical\n",
            "3    RANI3   Consumer Cyclical\n",
            "4    AMBP3         Industrials\n",
            "..     ...                 ...\n",
            "63  KLBN11     Basic Materials\n",
            "64   RDOR3          Healthcare\n",
            "65   BBDC4  Financial Services\n",
            "66   NTCO3  Consumer Defensive\n",
            "67   LREN3   Consumer Cyclical\n",
            "\n",
            "[68 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar DataFrame em um arquivo Excel\n",
        "df.to_excel('categorias_acoes.xlsx', index=False)"
      ],
      "metadata": {
        "id": "_awAR-IAvkHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL da página\n",
        "url = \"https://iseb3.com.br/carteiras-e-questionarios\"\n",
        "\n",
        "# Faz a requisição GET para a página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifica se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Extrai o conteúdo HTML da resposta\n",
        "    html_content = response.content\n",
        "\n",
        "    # Cria um objeto BeautifulSoup para fazer o parsing do HTML\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "    # Encontra o parágrafo que contém os nomes das empresas\n",
        "    paragraph = soup.find(\"p\", string=lambda text: text and text.startswith(\"Aeris\"))\n",
        "\n",
        "    # Extrai o texto do parágrafo\n",
        "    paragraph_text = paragraph.get_text(strip=True)\n",
        "\n",
        "    # Obtém o trecho de texto contendo as empresas\n",
        "    companies_text = re.search(r\"Aeris(.*?Weg\\.?)\", paragraph_text).group(0)\n",
        "\n",
        "    # Separa as empresas em uma lista\n",
        "    companies_list = re.split(r\",\\s*(?=.{2,}$)\", companies_text)\n",
        "\n",
        "    # Trata a exceção da última empresa\n",
        "    companies_list[-1] = companies_list[-1].rstrip(\".,\")\n",
        "    last_company = companies_list[-1].split(\" e \")\n",
        "    companies_list = companies_list[:-1] + last_company\n",
        "\n",
        "    # Exibe os nomes das empresas por linha\n",
        "    for company in companies_list:\n",
        "        print(company.rstrip(\".,\"))\n",
        "else:\n",
        "    print(\"Falha ao obter a página:\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZpQJIakxudF",
        "outputId": "e82c698d-54db-432a-856d-3c38b5b4f91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Aeris\n",
            "AES Brasil Energia\n",
            "Aliansce Sonae\n",
            "Ambev\n",
            "Ambipar\n",
            "Arezzo\n",
            "Azul\n",
            "B3 S.A\n",
            "Banco do Brasil\n",
            "Banco Pan\n",
            "Bradesco\n",
            "Braskem\n",
            "BRF\n",
            "BTG Pactual\n",
            "CCR\n",
            "Cemig\n",
            "Cia Brasileira de Alumínio\n",
            "Cia Brasileira de Distribuição\n",
            "Cielo\n",
            "Cogna Educação\n",
            "Copel\n",
            "Cosan\n",
            "CPFL\n",
            "CTEEP\n",
            "Dexco\n",
            "Diagnósticos da América\n",
            "Ecorodovias\n",
            "EDP\n",
            "Eletrobrás\n",
            "Eneva\n",
            "Engie\n",
            "Fleury\n",
            "Gafisa\n",
            "Grendene\n",
            "Guararapes\n",
            "Hypera\n",
            "Iochpe Maxion\n",
            "Irani Papel e Embalagem\n",
            "Itaú Unibanco\n",
            "Itausa\n",
            "Klabin\n",
            "Lojas Renner\n",
            "M. Dias Branco\n",
            "Magazine Luiza\n",
            "Marfrig\n",
            "Minerva\n",
            "Movida\n",
            "MRV\n",
            "Natura\n",
            "Neoenergia\n",
            "Raia Drogasil\n",
            "Raízen\n",
            "Rede D’or\n",
            "Rumo\n",
            "Sanepar\n",
            "Santander\n",
            "Santos Brasil\n",
            "Sendas\n",
            "Simpar\n",
            "SLC Agrícola\n",
            "Suzano\n",
            "Telefônica\n",
            "Tim\n",
            "Usiminas\n",
            "Vamos S.A\n",
            "Via\n",
            "Vibra\n",
            "Weg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Fazendo o upload do arquivo CSV\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Garantindo que somente um arquivo foi enviado\n",
        "if len(uploaded.keys()) != 1:\n",
        "  print(\"Por favor, faça o upload de apenas um arquivo de cada vez.\")\n",
        "else:\n",
        "  filename = list(uploaded.keys())[0]  # Nome do arquivo\n",
        "\n",
        "  # Lendo o arquivo CSV\n",
        "  # Supomos que a primeira linha é o título (skiprows=1 ignora a primeira linha) e a segunda linha contém os nomes das colunas\n",
        "  df = pd.read_csv(filename, skiprows=1)\n",
        "\n",
        "  # Imprimindo o título da tabela\n",
        "  with open(filename, 'r') as f:\n",
        "    title = f.readline().strip()  # Lê a primeira linha (título) e remove espaços desnecessários\n",
        "  print(f\"Título da Tabela: {title}\\n\")\n",
        "\n",
        "  # Filtrando as informações das empresas específicas\n",
        "  empresas = ['WEGE3.SA', 'SUZB3.SA', 'KLBN11.SA', 'RAIZ4.SA', 'NTCO3.SA']\n",
        "  filtered_df = df[df['Código'].isin(empresas)]\n",
        "\n",
        "  # Imprimindo as informações das empresas\n",
        "  print(filtered_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "_usDdILG-H-V",
        "outputId": "16490e14-0d3c-4bdb-a343-2c54dd059542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af491df4-a469-4cec-8079-0b2748fac9cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af491df4-a469-4cec-8079-0b2748fac9cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Coleta de Dados Marmitaria Delivery - Página2.csv to Coleta de Dados Marmitaria Delivery - Página2 (4).csv\n",
            "Título da Tabela: ISEE - Carteira do Dia 12/06/23,,,\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [Código, Ação, Qtde. Teórica, Part. (%)]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fundamentus\n",
        "!pip install requests-cache\n",
        "from fundamentus import get_papel_data\n",
        "\n",
        "# Definir os tickers das empresas\n",
        "tickers = ['WEGE3', 'SUZB3', 'KLBN11', 'RAIZ4', 'NTCO3']\n",
        "\n",
        "# Coletar dados fundamentalistas\n",
        "dados = {}\n",
        "for ticker in tickers:\n",
        "    papel_data = get_papel_data(ticker)\n",
        "    pl = papel_data['P/L']\n",
        "    dados[ticker] = pl\n",
        "\n",
        "# Imprimir o P/L das empresas\n",
        "for ticker, pl in dados.items():\n",
        "    print(f\"{ticker}: P/L = {pl}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uOqXkru0_yiT",
        "outputId": "aceda12c-f526-487b-98af-cae422e65830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fundamentus\n",
            "  Downloading fundamentus-0.2.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from fundamentus) (2.27.1)\n",
            "Collecting requests-cache>=0.5.2 (from fundamentus)\n",
            "  Downloading requests_cache-1.0.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from fundamentus) (1.5.3)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.10/dist-packages (from fundamentus) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from fundamentus) (0.8.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->fundamentus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->fundamentus) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->fundamentus) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->fundamentus) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->fundamentus) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->fundamentus) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->fundamentus) (3.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache>=0.5.2->fundamentus) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache>=0.5.2->fundamentus)\n",
            "  Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache>=0.5.2->fundamentus) (3.3.0)\n",
            "Collecting url-normalize>=1.4 (from requests-cache>=0.5.2->fundamentus)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache>=0.5.2->fundamentus) (1.1.1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache>=0.5.2->fundamentus) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->fundamentus) (1.16.0)\n",
            "Installing collected packages: url-normalize, cattrs, requests-cache, fundamentus\n",
            "Successfully installed cattrs-23.1.2 fundamentus-0.2.0 requests-cache-1.0.1 url-normalize-1.4.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests-cache in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (23.1.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (23.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (3.3.0)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (2.27.1)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (1.4.3)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache) (1.26.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache) (1.1.1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->requests-cache) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize>=1.4->requests-cache) (1.16.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fa67e02dd5a7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install fundamentus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install requests-cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfundamentus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_papel_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Definir os tickers das empresas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_papel_data' from 'fundamentus' (/usr/local/lib/python3.10/dist-packages/fundamentus/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}